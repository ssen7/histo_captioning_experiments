{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import HIPT_LGP_FC\n",
    "\n",
    "from HIPT.HIPT_4K.hipt_4k import HIPT_4K\n",
    "from HIPT.HIPT_4K.hipt_model_utils import get_vit256, get_vit4k, eval_transforms\n",
    "from HIPT.HIPT_4K.hipt_heatmap_utils import *\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    pretrained_weights256 = '/home/ss4yd/vision_transformer/HIPT/HIPT_4K/Checkpoints/vit256_small_dino.pth'\n",
    "    pretrained_weights4k = '/home/ss4yd/vision_transformer/HIPT/HIPT_4K/Checkpoints/vit4k_xs_dino.pth'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device256 = torch.device('cuda:0')\n",
    "        device4k = torch.device('cuda:1')\n",
    "    else:\n",
    "        device256 = torch.device('cpu')\n",
    "        device4k = torch.device('cpu')\n",
    "\n",
    "\n",
    "    ### ViT_256 + ViT_4K loaded independently (used for Attention Heatmaps)\n",
    "    model256 = get_vit256(pretrained_weights=pretrained_weights256, device=device256)\n",
    "    model4k = get_vit4k(pretrained_weights=pretrained_weights4k, device=device4k)\n",
    "\n",
    "    ### ViT_256 + ViT_4K loaded into HIPT_4K API\n",
    "    model = HIPT_4K(pretrained_weights256, pretrained_weights4k, device256, device4k)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at /home/ss4yd/vision_transformer/HIPT/HIPT_4K/Checkpoints/vit256_small_dino.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n",
      "# of Patches: 196\n",
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at /home/ss4yd/vision_transformer/HIPT/HIPT_4K/Checkpoints/vit4k_xs_dino.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n",
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at /home/ss4yd/vision_transformer/HIPT/HIPT_4K/Checkpoints/vit256_small_dino.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n",
      "# of Patches: 196\n",
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at /home/ss4yd/vision_transformer/HIPT/HIPT_4K/Checkpoints/vit4k_xs_dino.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n"
     ]
    }
   ],
   "source": [
    "hipt4k=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hipt4k.eval()\n",
    "\n",
    "region = Image.open('../HIPT/HIPT_4K/image_demo/image_4k.png')\n",
    "x = eval_transforms()(region).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "out = hipt4k.forward_asset_dict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 384])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(out['features_cls256']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Patches: 196\n",
      "Loading Pretrained Local VIT model...\n",
      "Done!\n",
      "Freezing Pretrained Local VIT model\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model=HIPT_LGP_FC(freeze_4k=True, pretrain_4k='vit4k_xs_dino', n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0900, -0.5607,  0.0396, -0.5876]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.2966, 0.1853, 0.3377, 0.1804]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[2]]),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(out['features_cls256']).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1260, -0.2569,  0.2892, -0.3795]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.2888, 0.1969, 0.3400, 0.1742]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[2]]),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.load('/project/GutIntelligenceLab/ss4yd/gtex_data/hipt4k_256cls_reps/GTEX-1117F-1026.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_256=torch.load('/project/GutIntelligenceLab/ss4yd/gtex_data/hipt4k_256cls_reps/GTEX-111CU-0326.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 256, 384])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_256.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1131, -0.2204, -0.0984, -0.4995]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.3260, 0.2335, 0.2638, 0.1767]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0]]),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(cls_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 384, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_256.unfold(1, 16, 16).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 192])\n",
      "torch.Size([56, 192])\n",
      "torch.Size([56, 192])\n",
      "torch.Size([56, 1]) torch.Size([56, 192])\n",
      "torch.Size([1, 56]) torch.Size([56, 192])\n",
      "torch.Size([1, 56]) torch.Size([56, 192])\n",
      "torch.Size([1, 192])\n",
      "torch.Size([1, 192])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1131, -0.2204, -0.0984, -0.4995]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_4096=model.local_vit(cls_256.unfold(1, 16, 16).transpose(1,2))\n",
    "print(h_4096.shape)\n",
    "h_4096 = model.global_phi(h_4096)\n",
    "print(h_4096.shape)\n",
    "h_4096 = model.global_transformer(h_4096.unsqueeze(1)).squeeze(1)\n",
    "print(h_4096.shape)\n",
    "A_4096, h_4096 = model.global_attn_pool(h_4096) \n",
    "print(A_4096.shape,h_4096.shape)\n",
    "A_4096 = torch.transpose(A_4096, 1, 0)\n",
    "print(A_4096.shape,h_4096.shape)\n",
    "A_4096 = F.softmax(A_4096, dim=1)\n",
    "print(A_4096.shape,h_4096.shape)\n",
    "h_path = torch.mm(A_4096, h_4096)\n",
    "print(h_path.shape)\n",
    "h_WSI = model.global_rho(h_path)\n",
    "print(h_WSI.shape)\n",
    "\n",
    "logits = model.classifier(h_WSI)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10.0",
   "language": "python",
   "name": "pytorch-1.10.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
